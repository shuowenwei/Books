\documentclass[MA, xcolor=dvipsnames]{wfuthesis} % MA or MS with in []

%\usepackage[top=1.0in,
%bottom=1.0in,
%left=1.5in,
%right=1.0in]{geometry}

\usepackage{amsfonts,amssymb,latexsym}
\usepackage{amsthm}  % used to make "proof" work
\usepackage{graphicx}
\usepackage{enumerate}
\usepackage{amsmath}  % added later
%\usepackage{setspace} % added later
\usepackage{color}    % added later
\everymath{\displaystyle} % added later
\usepackage{float}
\usepackage{tikz} % added later


\begin{document}

\newcommand{\dis}{\displaystyle}
\newcommand{\beq}{\begin{eqnarray}}
\newcommand{\eeq}{\end{eqnarray}}
%\newcommand{\lt}{\left}
%\newcommand{\rt}{\right}
\newcommand{\ra}{\rightarrow}
\newcommand{\cal}{\mathcal}
\newtheorem{thm1}{Theorem}[chapter]
\newtheorem{lem}{Lemma}
\newtheorem{thm}[thm1]{Theorem}
\newtheorem{definition}{Definition}
\newtheorem{cor}{Corollary}
\newcommand{\doublespace}{\addtolength{\baselineskip}{0.6\baselineskip}}
\newcommand{\singlespace}{\addtolength{\baselineskip}{-0.34\baselineskip}}
\newtheorem{conj}{\sc Conjecture}
\newtheorem{corollary}{Corollary}
\newcommand{\calI}{\mathcal{I}}
\newcommand{\calS}{\mathcal{S}}
\newcommand{\calT}{\mathcal{T}}
\newcommand{\calD}{\mathcal{D}}
\newcommand{\calR}{\mathcal{R}}
\newcommand{\calP}{\mathcal{G}}
\newcommand{\calC}{\mathcal{C}}



\title{Random walks with pheromone}
\author{Shuowen Wei}
\department{Mathematics}

\advisor{Kenneth Berenhaut, Ph.D.}
\chairperson{Jeremy Rouse, Ph.D.}
\member{Robert Erhardt, Ph.D.}
\date{August 2013}
\maketitle

\clearpage
%\pagenumbering{roman}  %with this line in TOC is page i,
%with this line out TOC is page ii


\acknowledgments  %is to come before table of contents

There are many people who helped to make this thesis possible. First
and foremost I would like to thank my advisor Dr. Berenhaut. It's a
privilege to work with you. Your guidance and support is invaluable.

I would like to thank my family, especially my mom, my dad and my two uncles.
This would not have been possible without your continuing support.

I would like to thank all math faculty, staff and graduate students.
Particularly Dr. Kirkman, Dr. Plemmons, Dr. Rouse, Dr. Erhardt, Dr. Allen, Dr. Jiang, Dr. Norris, Dr. Howards, Dr. Hu, Dr. Raynor, Dr. Erway, Ms. Connolly, Ms. Talbert, Mr. Wicker, Jiani Zhang, Panpan Zhang, Fei Yang, Mingyue Gao, Joe Patt, Katy Beeler, Kris Patton, Katherine Novacek, Marvin Jones, Scott Hubbard, Jesse Thorner, Sean Woodham, Ixavier Higgins, Andrea Bongco, Charly Stephens-Cohen, Nichole Smith, Ann Rogers, Kristy Mitchell, e.t.c.

In the end, I also would like to thank my lovely girlfriend Ling Ling and my great roommate Maxim Zalutskiy.


\listoftables

\listoffigures

\tableofcontents


\abstract
\noindent Shuowen Wei
\vspace{3mm}

\noindent In this thesis we are interested in random walks on graphs where transition probabilities from each vertex depend on values of a function, $f$, at neighboring nodes. The work is motivated by applications that arise in bio-inspired models wherein questions of dynamics are effected by pheromone trails. In Chapter 2, we discuss when the graph is the $n$-cycle, and the set of non-zero function values (the trail) is generated by visits of a simple random walk. We show that an optimal trail length is, in some sense, approximately one third of the cycle length. In Chapter 3, we consider non-contiguous subsets of the $n$-cycle. Here, a first random walker leaves maps (indicating a shortest path to a point $s$) in a possibly non-contiguous subset, $\calS$. We are then interested in minimizing the expected time required for a second uniformly random located second walker to reach $s$ (utilizing these maps when found). We show that the expected time is minimized when the maps are in a sense, evenly distributed on the cycle. The thesis concludes with some results (and a conjecture) regarding when $f$ values are determined by a large number of random walks departing from a point $s\in \mathbb{Z}$ and leaving accumulating pheromone.
%
%
%
%\noindent In this thesis we discussed random walks with pheromone on one dimensional toroidal graph, i.e.a cycle. We are interested in how a random walk can be affected by pheromone and how to optimize the performance of  a random-walk-based searching by determine the optimal amount or placements of pheromone. There are three different kinds of pheromone being studied, the consecutive non-accumulating pheromone, scattered non-accumulating pheromone and consecutive accumulating pheromone. For each case, we concluded with closed form formula and results, as well as a conjecture.
%
%(*****************
%The purpose of this thesis is to study random walks with pheromone, we are interested in how the expected amount of time for a random walker to reach a target is affected by pheromone.In this thesis, we begin by generally introducing the background of random walking based on pheromone. Next, we deeply discuss focus the best amount of non-accumulating pheromone to leave to minimize the time for a second walker to reach the target on a cycle, which was deposited with
%a set of contiguous pheromone, it turns out the optimal amount should be one third of the length of the cycle. Then, we consider about the scattered pheromone maps instead of contiguous pheromone, we find out that the optimal distribution of these maps is that when they are evenly distributed on the cycle. In the end, we propose two conjectures regrading the accumulating pheromone deposited on the $\mathbb{Z}$, we determined the bivariate generating function of such accumulated pheromone values and also figure out the probability ratio for an arbitrary node standing on the ``pheromone mountain", which showed up in a very neat form.
%**************)

%\vspace{3mm}
%\noindent 2nd Paragraph can go here if needed

\chapters

\chapter{Introduction}  % this is commends places
\pagenumbering{arabic}

In this thesis we are interested in random walks on graphs where transition probabilities from each vertex depend on values of a function, $f$, at neighboring nodes. We begin with the following example.

\noindent {\bf Example 1}. Consider a simple random walk on an $n \times m$ toroidal grid $G$, starting from some point $s\in G$. The walker leaves one bit of non-accumulating pheromone at each step until $k$ distinct vertices have been visited. Some time after this a second randomly placed walker begins
a random walk, but this walker prefers grid points with pheromone over
those without, in the sense that once it enters the connected component
with pheromone, it will not leave it. Large values of $k$ are essentially
equivalent to small values. Consider the distribution of the time it takes
for the second walker to reach the start point s. What is an optimal value of $k$ (in some sense)?
\qed

In Example 1, the graph under consideration is the toroidal grid (the standard Cayley graph for $\mathbb{Z}_n \times \mathbb{Z}_m$) and the function $f$ distinguishes points with pheromone from those without.

Now, let $X_1, X_2, X_3, \dots$ be a random walk on a connected graph $G=\left<V,E\right>$, and for each vertex $v$, set $N(v)$ to be the set of neighbours of $v$, i.e.
\beq
N(v)=\left\{w:\left(v,w\right) \in E\right\}.
\eeq

\noindent In addition suppose $f$ is a function $f:V\rightarrow \mathbb{Z}^{+}$, and that the associated transition probabilities for $\{X_i\}$ , $\{P_{x,y}\}$, depend only on $f$ restricted to the set $N\left(x\right)\cup x$.

Define
\beq
\calS=\left\{v: f(v)>0\right\}
\label{DefineCalS}
\eeq
\noindent to be the set of vertices with positive $f$-value. For fixed $X_0$, we will be interested in the expected amount of time, $T$, for the walker to reach a  vertex $s\in \calS$. In particular, we define the variables $T$, $T_1$ and $T_2$ via
\beq
T&=&\min \left\{t\geq 0: X_t=s \right\} \nonumber \\
T_1&=&\min \left\{t\geq 0: X_t\in \calS \right\} \nonumber \\
T_2&=&T-T_1, \nonumber \\
\label{DefofTT1T2}
\eeq
\noindent i.e., $T$ is the time required for the random walk to first visit $s$, $T_1$ is the time until the random walk enters $\calS$ for the first time ($T_1=0$ if $X_0\in \calS$), and $T_2$ is the time following entry to $\calS$ to arrive at $s$.

The thesis proceeds as follow. In Chapter 1, we are interested in the case where $G$ is an $n$-cycle, $\calC_n=\left\{0,1,2,\dots,n-1\right\}$ with edge set,
\beq
E&=&\{(0,1), (1,0), (1,2), (2,1), \dots,\nonumber \\
&&~~~
(n-2,n-1), (n-1,n-2), (n-1,0), (0,n-1)\}.
\eeq
\noindent $f(v)\in \{0,1\}$ for all $v\in \calC_n$, and $\calS$ is a sequence of consecutive vertices in $\calC_n$. We derive the total expected steps function $E\left[T\right]$, and use the result to obtain the optimal amount of pheromone to be left by a first walker (following a simple random walk) to minimize the expected time for a second walker (utilizing the pheromone) to locate the initial point of the first walker. In Chapter 2, we consider non-consecutive subsets $\calS \subseteq \calC_n$, wherein each $v\in \calS$ contains a ``map" indicating a shortest path from $v$ to $s$. We determine that an
optimal placement of the maps is ``evenly distributed" on the cycle. In Chapter 3, we consider contiguous subsets $\calS$ of the set of integers $\mathbb{Z}$ but allow the pheromone to be accumulated. We provide several results regarding the structure of pheromone deposited by several walkers departing from a point in $\mathbb{Z}$.

The concept of ``Gambler's Ruin" (see for instance \cite[Section 2.5]{ProbabilityAndStatistics3rd}) will be valuable in what follows. In particular, suppose $0 \leq i \leq k$ and two gamblers $\calP_1$ (with initial wealth $i$) and $\calP_2$ (with initial wealth $k-i$) are playing a coin tossing game repeatedly. If a result is a ``head", then $\calP_1$ will win one dollar; otherwise, $\calP_2$ will win one dollar. The game continues until the fortune of one (the loser) is zero and the other (the winner) $k$. We include the following well-known result (see for instance \cite{ProbabilityAndStatistics3rd}).

\begin{thm}
Suppose that the initial wealth of gambler $\calP_1$ is $i$ dollars and that of gambler $\calP_2$ is $k-i$ dollars, where $i$ is fixed and $0\leq i\leq k$, then
\beq
P(\calP_1 \mbox{ wins})=\frac{i}{k} ~~~\mbox{     and     }~~~
P(\calP_2 \mbox{ wins})=\frac{k-i}{k}.
\label{GamblerRuinFormula}
\eeq
\end{thm}
\noindent {\bf Proof}. First of all we have
\beq
P(\cal\calP_1 \mbox{ wins})&=&\frac{1}{2}P(\calP_1 \mbox{ wins }|~\calP_1 \mbox{ wins first toss})+\frac{1}{2}P(\calP_1 \mbox{ wins }|~\calP_1 \mbox{ loses first toss}). \nonumber \\
\label{aiiii}
\eeq
Let
\beq
a_i&=&P(\calP_1 \mbox{ wins } |~\calP_1 \mbox{ begins with wealth } i),
\label{ai}
\eeq
\noindent then from (\ref{aiiii}) we have
\beq
a_i&=&\frac{1}{2}a_{i+1}+\frac{1}{2}a_{i-1},~~~1\leq i\leq k-1
\label{aiii}
\eeq
\noindent Rewriting Equation (\ref{aiii}) using $a_i=\frac{1}{2}a_i+\frac{1}{2}a_i$, we have
\beq
a_{i+1}-a_{i}&=&a_{i}-a_{i-1}
\label{aii}
\eeq
\noindent Note that $a_0=0$ and $a_k=1$, thus, by Equation (\ref{aii}) we have
\beq
a_2-a_1&=&a_1-0=a_1 \nonumber \\
a_3-a_2&=&a_2-a_1 =a_1  \nonumber \\
&\vdots& \nonumber \\
a_i-a_{i-1}&=&a_{i-1}-a_{i-2}=a_1 \nonumber \\
&\vdots& \nonumber \\
a_{k-1}-a_{k-2}&=&a_{k-2}-a_{k-3}=a_1 \nonumber \\
1-a_{k-1}&=&a_{k-1}-a_{k-2}=a_1 \nonumber \\
\label{GamblerRuin}
\eeq
\noindent Summing Equation (\ref{GamblerRuin}) we obtain $1-a_1=(k-1)a_1$, and hence $a_1=1/k$. In turn, it follows from the first equality in (\ref{GamblerRuin}) that $a_2=2/k$, similarly that $a_3=3/k$, and so on. In this way, we obtain the solution
\beq
a_i=\frac{i}{k},
\eeq
\noindent for $i=1,2, \dots, k-1$. Thus $P(\calP_1 \mbox{ beats } \calP_2)=\frac{i}{k}$ and $P(\calP_2 \mbox{ beats } \calP_1)=\frac{k-i}{k}$.
\qed

We now turn to consideration of contiguous set $\calS$ on the cycle.

\chapter{Contiguous sets $\calS$ on the $n$-cycle (non-accumulating pheromone)}

In this chapter, we will discuss when the graph $G$ is the $n$-cycle, $\calC_n$, and the set $\calS$ is contiguous. Intuitively, imagine a first (simple random) walker departing from $s\in \calC_n$ and leaving one
bit of non-accumulating pheromone before stepping away from each vertex, until $k$ bits of pheromone are left. As in Example 1, we are interested in the optimal number of bits of pheromone the first walker should leave in order that the second will spend the least steps to find s, starting from a random initial position.

It is clear that the pheromone
area, $\calS$, will be connected (as it arises from a random walk). We will show (see Lemma \ref{Lemma3}) that $s$ is equally likely to be any of the $k$ positions relative to the left-most point in the pheromone area.

Now suppose $\calC_n$ is an $n$-cycle, and $f$ satisfies $f\left(x\right)\in\{0, 1\}$ for $x \in \calC_n$. In addition, suppose $\{X_i\}$ is a random walk on $\calC_n$ with the following transition probabilities
\beq
P_{x,x+1}=P_{x,x-1}&=&1/2,~~\mbox{if $f(x-1)=f(x+1)$},  \nonumber \\
P_{x,x+1}&=&1,~~\mbox{if $f(x-1)=0, f(x+1)=1$},  \nonumber \\
P_{x,x-1}&=&1,~~\mbox{if $f(x+1)=0, f(x-1)=1$},  \nonumber \\
P_{x,y}&=&0,~~\mbox{otherwise}.  \nonumber \\
\label{TransisationFunction}
\eeq

As in (\ref{DefineCalS}) let $S=\left\{i:f(i)=1\right\}$, and suppose $s\in \calS$. Recall,
$T= \min \left\{t: X_t=s \right\}$. We will prove the following theorem.


\begin{thm}
If $\calS$ is the set of the first $k$ vertices visited by a simple random walk beginning at vertex $s$, and $X_0$ is uniformly random within $\calC_n$,
then
\beq
E(T)&=&\frac{1}{6n}\left[\left(n-k-2\right)\left(n-k-1\right)\left(n-k\right)+6\left(n-k-2\right)+\left(n-k\right)\left(k-1\right)\left(2k-1\right)\right] \nonumber \\
\label{ForumulaOfET}
\eeq
\label{Chapter1Thm1}
\end{thm}
We have the following corollary regarding the optimal amount of pheromone to be deposited.
\begin{cor}
Suppose $n$ is fixed and $k^*$ minimizes $E(T)$, under the assumptions in the statement of Theorem \ref{ForumulaOfET}. Then
\beq
\lim_{n \to +\infty}\frac{k^*}{n}&=&\frac{1}{3}.
\eeq
\label{corollary1}
\end{cor}
In proving Theorem \ref{Chapter1Thm1}, we will employ the following three lemmas. Recall from (\ref{DefofTT1T2}) that $T_1=\min \left\{t: X_t \in \calS \right\}$.

\begin{lem}
If $\calS=\left\{n-k,n-k+1,\dots,n-1\right\}$. Then
\beq
\sum\limits_{i\in \calC_n\setminus S} E\left(T_1|X_0=i\right) &=& \frac{1}{6}r\left(r+1\right)\left(r+2\right)+r+2,
\label{Ar}
\eeq
\noindent where $r\stackrel{def}{=}n-k-2$.
\label{Lemma1}
\end{lem}

\noindent{\bf Proof}. First, let
\beq
a_i \stackrel{def}{=} E\left(T_1|X_0=i\right),~~~0\leq i\leq r+1,
\label{aI}
\eeq
\noindent and define $A$ via
\beq
A&=&\sum\limits_{i=0}^{r+1} a_i,~~~0\leq i\leq r+1.
\eeq

The non-pheromone area, $C\setminus \calS$, with a total length of $|C|-|\calS|=n-k=r+2$, is shown in the table below,
\begin{table}[H]
\begin{center}
\begin{tabular}{| c | c | c | c | c | c | c | c | c | c |}
  \hline
    $f\left(i\right)$&$1\dots1$&$0$ & $0$ & $0$ & $ \dots $ & $0$ & $0$ & $0$ & $1\dots1$
   \\\hline
    $E(T_1|X_0=i)$&$0$&$a_0$ & $a_1$ & $a_2$ & $ \dots $ & $a_{r-1}$ & $a_r$ & $a_{r+1}$ & $0$
  \\  \hline
\end{tabular}
\end{center}
\end{table}
\noindent where $a_0=a_{r+1} = 1$ by Equation (\ref{TransisationFunction}). Note that, by conditioning,
\beq
a_i&=&\frac{1}{2}\left(a_{i-1}+1\right)+\frac{1}{2}\left(a_{i+1}+1\right), ~~~ 1\leq i \leq r.
\label{Formilar4ai}
\eeq

\noindent For $r=1$, we have $a_1 = 2$, while for $r \geq 2$, Equation (\ref{Formilar4ai}) gives
\beq
a_1 &=& \frac{1}{2}\left(1+1\right) + \frac{1}{2}\left(a_2+1\right) \nonumber \\
a_2 &=& \frac{1}{2}\left(a_1 + 1 \right) + \frac{1}{2}\left(a_3+1\right) \nonumber \\
&\vdots& \nonumber \\
a_i &=& \frac{1}{2}\left(a_{i-1} + 1 \right) + \frac{1}{2}\left(a_{i+1}+1\right) \nonumber \\
&\vdots& \nonumber \\
a_{r-1} &=& \frac{1}{2}\left(a_{r-2} + 1 \right) + \frac{1}{2}\left(a_r+1\right) \nonumber \\
a_r &=& \frac{1}{2}\left(a_{r-1} + 1 \right) + \frac{1}{2}\left(1+1\right). \nonumber\\
\eeq
\noindent  Summarizing in matrix form gives
\beq
\begin{bmatrix}
1 & -1/2 & 0 & 0 & \cdots & 0 \\
-1/2 & 1 & -1/2 & 0 & \cdots & 0 \\
0 & -1/2 & 1 & -1/2 & \cdots & 0 \\
\vdots & \vdots & \ddots & \ddots & \ddots & \vdots \\
0 & 0 & \cdots &-1/2  & 1 &-1/2 \\
0 & 0 & \cdots & 0  &-1/2  & 1 \\
\end{bmatrix}_{r \times r}
\times
\left[\begin{array}{c} a_1 \\ a_2 \\ a_3 \\ \vdots \\ a_{r-1} \\ a_r \end{array} \right] =
\left[ \begin{array}{c} 3/2 \\ 1 \\ 1 \\ \vdots \\ 1 \\ \ 3/2 \end{array} \right].
\label{amat}
\eeq

\noindent The values of $a_i$ for small $r$ are
\begin{center}
\begin{tabular}{| l | c | c | c | c | c | c | c | c | c | c | c |}
  \hline
$r/a_i$ &$a_1$&$a_2$&$a_3$&$a_4$&$a_5$&$a_6$&$a_7$&$a_8$&$a_9$&$a_{10}$&$a_{11}$\\ \hline
    $r=1$ & $2$ & $$ & $$ & $$ & $$ & $$ & $$ & $$ & $$ & $$ & $$  \\ \hline
    $r=2$ & $3$ & $3$ & $$ & $$ & $$ & $$ & $$ & $$ & $$ & $$ & $$ \\   \hline
    $r=3$ & $4$ & $5$ & $4$ & $$ & $$ & $$ & $$ & $$ & $$ & $$ & $$\\  \hline
    $r=4$ & $5$ & $7$ & $7$ & $5$ & $$ & $$ & $$ & $$ & $$ & $$ & $$\\
  \hline
    $r=5$ & $6$ & $9$ & $10$ & $9$ & $6$ & $$ & $$ & $$ & $$ & $$ & $$\\
  \hline
    $r=6$ & $7$ & $11$ & $13$ & $13$ & $11$ & $7$ & $$ & $$ & $$ & $$  & $$\\
  \hline
    $r=7$ & $8$ & $13$ & $16$ & $17$ & $16$ & $13$ & $8$ & $$ & $$ & $$ & $$\\
  \hline
    $r=8$ & $9$ & $15$ & $19$ & $21$ & $21$ & $19$ & $15$ & $9$ & $$ & $$ & $$\\
  \hline
    $r=9$ & $10$ & $17$ & $22$ & $25$ & $26$ & $25$ & $22$ & $17$ & $10$ & $$ & $$\\
  \hline
    $r=10$ & $11$ & $19$ & $25$ & $29$ & $31$ & $31$ & $29$ & $25$ & $19$ & $11$ & $$ \\
  \hline
    $r=11$ & $12$ & $21$ & $28$ & $33$ & $36$ & $37$ & $36$ & $33$ & $28$ & $21$ & $12$ \\ \hline
%$\vdots$&$\vdots$&$\vdots$&$\vdots$&$\vdots$&$\vdots$&$\vdots$&$\vdots$&$\vdots$&$\vdots$&$\vdots$&$\vdots$&$\ddots$\\
%  \hline
\end{tabular}
\end{center}

It is not difficult to verify that the general formula for $a_i$ is
\beq
a_i=i\left(r+1\right)-i^2+1.
\label{air}
\eeq
\noindent In particular, $a_0=a_{r+1}=1$, and for $1\leq i\leq r$
\beq
\frac{1}{2}\left(a_{i-1}+1\right)+\frac{1}{2}\left(a_{i+1}+1\right)
&=&\frac{1}{2}\left[\left(i-1\right)\left(r+1\right)-\left(i-1\right)^2+1+1\right] \nonumber \\
&&+\frac{1}{2}\left[\left(i+1\right)\left(r+1\right)-\left(i+1\right)^2+1+1\right] \nonumber \\
&=&\frac{2i}{2}\left(r+1\right)-\frac{\left(i-1\right)^2+\left(i+1\right)^2}{2}+2 \nonumber \\
&=&i\left(r+1\right)-i^2+1 \nonumber \\
&=&a_i.
\label{Verifyai}
\eeq
Employing (\ref{air}),
\beq
A&=&\sum\limits_{i=0}^{r+1} a_i = 1+ a_1+a_2+a_3+ \dots +a_r+1\nonumber \\
&=&\left(r+1\right)\sum\limits_{i=1}^{r}i-\sum\limits_{i=1}^{r}i^2+r+2 \nonumber \\
&=&\left(r+1\right)\frac{r\left(1+r\right)}{2}-\frac{1}{6}r\left(r+1\right)\left(2r+1\right)+r+2 \nonumber \\
&=&\frac{1}{6}r\left(r+1\right)\left(r+2\right)+r+2,
\label{ArOdd}
\eeq
\noindent and (\ref{Ar}) holds. In the third equality in (\ref{ArOdd}), we applied the formulas
$\sum\limits_{i=1}^{n}i = \frac{n\left(1+n\right)}{2}$
and $\sum\limits_{i=1}^{n}i^2 = \frac{1}{6}n\left(n+1\right)\left(2n+1\right)$.
\qed

\begin{lem}
If $\calS=\left\{\sigma_0+1,\sigma_0+2,\dots,\sigma_0+l,s,\sigma_1-m,\dots,\sigma_1-2,\sigma_1-1\right\}$, where $f(\sigma_0)=f(\sigma_1)=0$, then $l+m+1=k$,
\beq
E\left(T|X_0 = \sigma_0+i\right)&=&l^2-\left(i-1\right)^2, \\
E\left(T|X_0 = \sigma_1-i\right)&=&m^2-\left(i-1\right)^2,
\eeq
\noindent and in particular
\beq
\sum\limits_{i=1}^{l}E\left(T|X_0=\sigma_0+i\right)&=&\frac{1}{6}l\left(l+1\right)\left(4l-1\right)\\
\sum\limits_{i=1}^{m}E\left(T|X_0=\sigma_1-i\right)&=&\frac{1}{6}m\left(m+1\right)\left(4m-1\right).
\eeq
\label{Lemma2}
\end{lem}

\noindent{\bf Proof}.
Let
\beq
b_i\stackrel{def}{=} E\left(T|X_0=\sigma_0+i\right),~~~1\leq i\leq l \label{bi},\\
c_i\stackrel{def}{=} E\left(T|X_0=\sigma_1-i\right),~~~1\leq i\leq m\label{ci},
\eeq

\noindent define $B$ and $C$ via
\beq
B&=&\sum\limits_{i=1}^{l} b_i,~~~1\leq i\leq l \label{BL}, \\
C&=&\sum\limits_{i=1}^{m} c_i,~~~1\leq i\leq m \label{CM}.
\eeq
We have the scenario depicted in Table 2.1.
\begin{table}[H]
\begin{center}
\begin{tabular}{| c | c | c | c | c | c | c | c | c | c | c| c|c | c | c| c|}
  \hline
$i$&$\sigma_0+1$&$\sigma_0+2$&$\cdots$&$\sigma_0+l$&$s$&$\sigma_1-m$&$\cdots$& $\sigma_1-2$&$\sigma_1-1$
  \\  \hline
$E(T_2|X_0=i)$&$b_1$&$b_2$&$\cdots$&$b_l$&$0$&$c_m$&$\cdots$& $c_2$&$c_1$
 \\  \hline
\end{tabular}
\end{center}
\caption[The value of $E\left(T_2|X_0=i\right)$ for $i\in \calS$.]{The value of $E\left(T_2|X_0=i\right)$ for $i\in \calS$, in the statement of Lemma \ref{Lemma2}.}
\end{table}
\noindent First, when $k=1$, $l=m=0$, and when $l=1$, $b_1=1$. When $l\geq 2$, by Equation (\ref{TransisationFunction}) we have $b_1=1+b_2$.

\noindent For $2\leq i \leq l$, we have
\beq
b_i&=&\frac{1}{2}\left(b_{i-1}+1\right)+\frac{1}{2}\left(b_{i+1}+1\right),~~~ 2\leq i \leq l.
\label{Formular4bi}
\eeq
Solving the resulting linear system for $b_1,b_2, \dots,b_l$,
\begin{center}
$
\begin{bmatrix}
1 & -1 & 0 & 0 & \cdots & 0 \\
-1/2 & 1 & -1/2 & 0 & \cdots & 0 \\
0 & -1/2 & 1 & -1/2 & \cdots & 0 \\
\vdots & \vdots & \ddots & \ddots & \ddots & \vdots \\
0 & 0 & \cdots &-1/2  & 1 &-1/2 \\
0 & 0 & \cdots & 0  &-1/2  & 1 \\
\end{bmatrix}_{l \times l}
\times
\left[\begin{array}{c} b_1 \\ b_2 \\ b_3 \\ \vdots \\ b_{l-1} \\ b_l \end{array} \right]
=
\left[ \begin{array}{c} 1 \\ 1 \\ 1 \\ \vdots \\ 1 \\ 1 \end{array} \right],
$
\end{center}

\noindent for small $l$, gives the values in Table \ref{ValuebSmalll}.
\begin{table}[H]
\begin{center}
\begin{tabular}{| l | c | c | c | c | c | c | c | c | c | c | }
  \hline
    $l/b_i$&$b_1$&$b_2$&$b_3$&$b_4$&$b_5$&$b_6$&$b_7$&$s$%&$c_7$&$c_6$&$c_5$&$c_4$&$c_3$&$c_2$&$c_1$&$r$\\
  \\ \hline
    $1$ & $1$ & $$ & $$ & $$ & $$ &$$ &$$ &$$ %&$13$ & $24$&$33$&$40$&$45$&$48$&$49$&$7$\\
  \\ \hline
    $2$ & $4$ & $3$ & $$ & $$ &$$ &$$ &$$ &$$ %& $$ & $11$ & $20$&$27$&$32$&$35$&$36$&$6$\\
  \\ \hline
    $3$ & $9$&$8$ & $5$ & $$ &$$ &$$ &$$ &$$ %& $$ & $$ & $9$ & $16$ & $21$&$24$&$25$&$5$\\
  \\ \hline
    $4$ & $16$&$15$ &$12$ &$7$& $$ &$$ &$$ &$$ %&$$ & $$ & $$&$7$&$12$ &$15$& $16$ & $4$\\
  \\ \hline
    $5$ & $25$&$24$ & $21$ & $16$ & $9$&$$ &$$ &$$ %&$$ &$$ &$$ & $$ & $5$&$8$&$9$&$3$\\
  \\ \hline
    $6$ & $36$&$35$&$32$&$27$&$20$&$11$ &$$ &$$ %&$$ && $$ & $$ & $$ & $3$ & $4$ & $2$\\
  \\ \hline
    $7$ & $49$&$48$&$45$&$40$&$33$&$24$&$13$ &$$ %&$$ &$$ & $$ & $$ & $$ & $$ & $1$ & $1$\\
  \\ \hline
\end{tabular}
\end{center}
\caption{Values of $b_i$ for small $l$.}
\label{ValuebSmalll}
\end{table}
We have $b_1=l^2$ and in general,
\beq
b_i &=&l^2-\left(i-1\right)^2,~~~1\leq i\leq l,
\eeq
\noindent as can be verified via
\beq
\frac{1}{2}\left(b_{i-1}+1\right)+\frac{1}{2}\left(b_{i+1}+1\right)&=&\frac{1}{2}\left(l^2-\left(i-1-1\right)^2+1\right)+\frac{1}{2}\left(l^2-\left(i+1-1\right)^2+1\right)  \nonumber\\
&=&l^2+1-\frac{1}{2}\left(\left(i-2\right)^2+i^2\right) \nonumber \\
&=&l^2-\left(i-1\right)^2 \nonumber \\
&=&b_i. \nonumber \\
\eeq
\noindent Then, for $B$ in (\ref{BL}), we have
\beq
B&=&\sum\limits_{i=1}^l b_i \nonumber \\
&=& b_1+b_2+b_3+ \cdots + b_{l-1}+b_l \nonumber \\
&=&l\left(l^2\right)- 1^2-2^2-3^2- \cdots - \left(l-1\right)^2 \nonumber \\
&=&l^3-\frac{1}{6}\left(l-1\right)\left(l-1+1\right)\left(2\left(l-1\right)+1\right) \nonumber \\
&=&l^3 - \frac{1}{6}l\left(l-1\right)\left(2l-1\right) \nonumber \\
&=&\frac{1}{6}l\left(l+1\right)\left(4l-1\right).
\eeq

It follows, similarly, that $c_i=m^2-\left(i-1\right)^2$, $C=\sum\limits_{i=1}^{m}c_i=\frac{1}{6}m\left(m+1\right)\left(4m-1\right)$, and the result is proven.
\qed


As mentioned, we will employ the following lemma.

\begin{lem}
Suppose $\calS=\left\{s_1+1, s_1+2, \dots, s_1+k\right\}$ is the set of the first $k$ distinct vertices visited by a random walk starting at vertex $s$, then $s_1$ is uniformly distributed in $\{s-k,s-(k-1),\dots,s-2,s-1\}$.
\label{Lemma3}
\end{lem}
\noindent{\bf Proof}. Suppose $s_1=s-i$, i.e. $s=s_1+i$, as in the table below.
\begin{table}[H]
\begin{center}
\begin{tabular}{| c | c | c | c | c | c | c | c | c| c | c | c |}
  \hline
     $s_1+1$&$s_1+2$&$\cdots$&$s=s_1+i$&$\cdots$& $s_1+k-1$&$s_1+k$
  \\  \hline
%   position &$1$&$2$&$\cdots$&$i$&$\cdots$& $k-1$&$k$
%  \\  \hline
\end{tabular}
\end{center}
\caption{The relative position of $s$ in $\calS$.}
\end{table}
Note that there are only two scenarios in which the set $\calS$ can be generated (given the random walk begins at $s=s_1+i$).

1. The leftmost vertex in $\calS$, $s_1+1$, is reached before the rightmost vertex, $s_1+k$, and following that the vertex $s_1+k$ is visited before $s_1$.

2. The rightmost vertex in $\calS$, $s_1+k$, is reached before the leftmost vertex, $s_1+1$, and following that the vertex $s_1+1$ is visited before $s_1+k+1$.

By Theorem \ref{GamblerRuinFormula}, we have
\beq
P(s_1=s-i)
&=&\frac{k-i}{k}\,\frac{1}{k}+\frac{i}{k}\,\frac{1}{k} \nonumber \\
&=&\frac{1}{k},
\eeq
\noindent and the lemma is proven.
\qed

We now prove Theorem \ref{Chapter1Thm1}.

\noindent{\bf Proof of Theorem \ref{Chapter1Thm1}}.
Without loss of generality, we can shift the vertices in the cycle so that $s$ is located as in the table below. In addition, employing Lemma \ref{Lemma3}, we can assume that $s$ is equally likely to be at any of the positions $r+2, r+3, \dots, n-1$. Assume that $s$ is positioned as in the table below.

\begin{table}[H]
\begin{center}
\begin{tabular}{| c | c | c | c | c | c | c | c | c| c | c | c|c |c|c |}
  \hline
$0$ & $1$ & $2$ & $ \cdots $ & $r$&$r+1$ & $r+2$ &$\cdots$&$s-1$& $s$ &$s+1$& $ \cdots $ & $n-2$ & $n-1$  \\ \hline
$a_0$ & $a_1$ & $a_2$&$\cdots$ & $a_r$ & $a_{r+1}$ & $b_1$ &$\cdots$&$b_l$& $0$ &$c_{m}$& $ \cdots $ & $c_2$ & $c_1$  \\ \hline
\end{tabular}
\caption[The position of $s$ in the proof of Theorem \ref{Chapter1Thm1}.]{The position of $s$ in the proof of Theorem \ref{Chapter1Thm1}. Here the values in the top row indicate $X_0$, and that in the second row indicate $a_i$, $b_i$ and $c_i$, as in (\ref{aI}), (\ref{bi}) and (\ref{ci}) respectively, as appropriate.}
\end{center}
\end{table}

Employing the notation in the proofs of Lemmas \ref{Lemma1} and \ref{Lemma2}, with
$A=\sum\limits_{i=0}^{r+1}a_i$, $B=\sum\limits_{i=1}^{l}b_i$ and $C=\sum\limits_{i=1}^{m}c_i$, we have from Lemmas \ref{Lemma1} and \ref{Lemma2} that
\beq
A&=&\frac{1}{6}r\left(r+1\right)\left(r+2\right)+r+2,~~~0\leq i \leq r+1 \nonumber \\
B&=&\frac{1}{6}l\left(l+1\right)\left(4l-1\right),~~~1\leq i \leq l \nonumber \\
C&=&\frac{1}{6}m\left(m+1\right)\left(4m-1\right),~~~1\leq i \leq m, \nonumber \\
\label{BOfsCOfS}
\eeq
\noindent where $l=s-r-3$ and $m=n-s-1$.

Recall Equation (\ref{DefofTT1T2}), and define the expected number of steps required by the walker to reach vertex $s$ starting at vertex $i$ as
\beq
\tau_{i,j} &=& E\left[T|X_0=i, s=j\right].
\eeq
\noindent Then, treating $B$ and $C$ in (\ref{BOfsCOfS}) as functions of $s$, we have
\beq
E(T)&=&\frac{1}{nk}\sum\limits_{r+2\leq s \leq n-1} \left[\sum\limits_{0\leq i \leq r+1}\tau_{i,j} + \sum\limits_{r+2\leq i\leq s-1}\tau_{i,j} + \sum\limits_{s+1\leq i \leq n-1}\tau_{i,j} \right] \nonumber \\
&\stackrel{def}{=}& \frac{1}{nk}\sum\limits_{r+2\leq s \leq n-1}\left[S_O(s)+B(s)+C(s)\right],
\label{FNK}
\eeq
\noindent say.

We have, for fixed $s\in \calS$,
\beq
B(s)&=&\frac{1}{6}\left(s-r-3\right)\left(s-r-2\right)\left(4s-4r-13\right)
\eeq
\noindent and,
\beq
C(s)&=&\frac{1}{6}\left(n-s-1\right)\left(n-s\right)\left(4n-4s-5\right).
\eeq
\noindent and employing Theorem \ref{GamblerRuinFormula}, we have
\beq
S_O\left(s\right)
&=&\sum\limits_{0\leq i\leq r+1}\tau_{i,j} \nonumber \\
&=&\sum\limits_{0\leq i\leq r+1}\left(a_i+\frac{i}{r+1}b_1+\frac{r+1-i}{r+1}c_1\right) \nonumber \\
&=&A+\left(\frac{r}{2}+1\right)\left(b_1+c_1\right) \nonumber \\
&=&\frac{1}{6}r\left(r+1\right)\left(r+2\right)+r+2+
    \left(\frac{r+2}{2}\right)\left(\left(s-r-3\right)^2+\left(n-s-1\right)^2\right). \nonumber \\
\eeq
\noindent Thus,
\beq
E(T)&=&\frac{1}{k}\sum\limits_{r+2\leq s \leq n-1}\left[\sum\limits_{0\leq i \leq r+1}\tau_{i,j} +\sum\limits_{r+2\leq i\leq s-1}\tau_{i,j} +\sum\limits_{s+1\leq i \leq n-1}\tau_{i,j} \right] \nonumber \\
&=&\frac{1}{k}\sum\limits_{r+2\leq s \leq n-1}\left[\frac{1}{6n}\left(s-r-3\right)\left(s-r-2\right)\left(4s-4r-13\right)\right. \nonumber \\
&&\left.+\frac{1}{6n}\left(n-s-1\right)\left(n-s\right)\left(4n-4s-5\right)+\frac{1}{6n}r\left(r+1\right)\left(r+2\right)\right. \nonumber \\
&&\left.+\frac{r+2}{n}+
    \left(\frac{r+2}{2n}\right)\left(\left(s-r-3\right)^2+\left(n-s-1\right)^2\right)\right] \nonumber \\
&=&\frac{1}{6nk}\sum\limits_{r+2\leq s \leq n-1}\left[\left(s-r-3\right)\left(s-r-2\right)\left(4s-4r-13\right)\right. \nonumber \\
&&\left.+\left(n-s-1\right)\left(n-s\right)\left(4n-4s-5\right)+r\left(r+1\right)\left(r+2\right)\right. \nonumber \\
&&\left.+6r+12+\left(3r+6\right)\left(\left(s-r-3\right)^2+\left(n-s-1\right)^2\right)\right] \nonumber \\
&=&\frac{1}{6n}\left[ r\left(r+1\right)\left(r+2\right)+6r+\left(r+2\right)\left(k-1\right)\left(2k-1\right)+2\left(k+1\right)\left(k-1\right)^2+12 \right]. \nonumber \\
\eeq
\qed

We are now in a position to prove Corollary \ref{corollary1}.

\noindent {\bf Proof of Corollary 1}. Denote
\beq
g(k)=g_n\left(k\right)\stackrel{def}{=} E(T).
\eeq
Employing Theorem \ref{Chapter1Thm1}, we have
\beq
g'\left(k\right)&=&\frac{1}{6n}\left[-\left(n-k-1\right)\left(n-k\right)-\left(n-k-2\right)\left(n-k\right)-\left(n-k-2\right)\left(n-k-1\right)\right.\nonumber \\
&&\left.-6-\left(k-1\right)\left(2k-1\right)+\left(n-k\right)\left(2k-1\right)+2\left(n-k\right)\left(k-1\right)\right. \nonumber \\
&&\left.+2\left(k-1\right)^2+4\left(k+1\right)\left(k-1\right) \right], \nonumber
\eeq
\noindent and hence
\beq
g'(k)&=&\frac{1}{6n}\left[-\left(k^2+k\left(1-2n\right)+n^2-n\right)- \left(k^2+k\left(2-2n\right)+n^2-2n\right)\right.  \nonumber \\
&&\left.-\left(k^2+k\left(3-2n\right)+n^2-3n+2\right)-6-\left(2k^2-3k+1\right)\right. \nonumber \\
&&\left.+\left(-2k^2+k\left(1+2n\right)-n\right)+2\left(-k^2+k\left(1+n\right)-n\right)\right. \nonumber \\
&&\left.+2k^2-4k+2+4k^2-4 \right] \nonumber \\
&=&\frac{1}{6n}\left[-3k^2+k\left(10n-4\right)-\left(3n^2-3n+11\right) \right].
\eeq
\noindent Solving $g'(k) = 0$, we obtain
\beq
k&=&\frac{\left(10n-4\right)\pm\sqrt{\left(10n-4\right)^2-12\left(3n^2-3n+7\right)}}{2\times3} \nonumber \\
&=&\frac{\left(5n-2\right)\pm \sqrt{16n^2-11n-29}}{3}.
\eeq
\noindent Note that $0<k<n$, and only
\beq
k_{-}&=&\frac{\left(5n-2\right)-\sqrt{16n^2-11n-29}}{3}
\label{kstar}
\eeq

\noindent meets the condition. Note that
\beq
g''(k)&=&\frac{1}{6n}(-6k+10n-4)
\eeq
\noindent and
\beq
g''\left(k_{-}\right)&=&\frac{\sqrt{16n^2-11n-29}}{6n}>0,
\label{SecondDeviativeOfG2prime}
\eeq
\noindent for $n > 1$. The result then follows by dividing by $n$ and letting $n$ tend to infinity in (\ref{kstar}).
\qed

We conclude with plots of $T_1$, $T_2$ and $T$ for $n=20$ and $k\in \{1,2,\dots,19\}$. Results are averaged over $N=1000000$ realizations of $X_0, X_1, \dots, $ with $s$ uniformly random in $\calC_n$, $\calS$ (with $|\calS|=k$) generated by a simple random walk starting at $s$ and $X_0$ uniformly random in $\calC_n$. Note that in this case, $k_{-}= (98-\sqrt{6151})/3 \approx 6.498$.

\begin{figure}[H]
\begin{center}
\includegraphics[width=0.8\textwidth]{20-1000000.pdf}
\caption[Simulations based on $N=1,000,000$ realizations of $X_t$ for $n=20$ and $1\geq k\geq 19$.]{Simulations based on $N=1,000,000$ realizations of $X_0, X_1, \dots,$ for $n=20$ and values of $k$ in the set $\{1,2,\dots,19\}$.}
\label{fig:1}
\end{center}
\end{figure}

\chapter{Non-contiguous sets $\calS$ on the $n$-cycle (scattered shortest-path maps)}

In this chapter, we consider non-contiguous subsets $\calS$ of the $n$-cycle, $\calC_n$, where the transition probability matrix $P$ is a simple random walk. Here we are interested in the quantity
\beq
W=T_1+dist\left(X_{T_1},s\right),
\eeq

\noindent where $T_1=\min \left\{t: X_t\in \calS \right\}$  as in (\ref{DefofTT1T2}), and $dist(\alpha,\beta)$ is the shortest-path distance between vertices $\alpha$ and $\beta$. In particular, we will consider
\beq
E(W|X_0=i).
\label{EquationMap1}
\eeq

\noindent Intuitively, imagine a first walker
departing from $s\in \calC_n$ and leaving ``maps" to $s$ (indicating a shortest path to $s$), at $k$ selected vertices in the cycle. The quantity in Equation (\ref{EquationMap1}) is then the expected time to reach $s$, starting at $X_0=i \in \calC_n$.

In proving the main theorem of this chapter we will employ the following definition.

\noindent {\bf Definition}. The set $\calS=\left\{s_i\right\}_{1\leq i\leq k}$ with $s_1< s_2< \dots < s_k$ is said to be ``evenly distributed" on the cycle $\calC_n$ if for
\beq
\calT=\{s_2-s_1,s_3-s_2,\dots,s_k-s_{k-1},s_1-s_k+n\},
\eeq
\noindent we have $\max(\calT)-\min(\calT)\leq 1$.
\qed

We will prove the following theorem.

\begin{thm}
The function $G$ defined via
\beq
G(\calS)&=&\frac{1}{n}\sum\limits_{i\in \calC_n} E\left(W|X_0=i\right),~~~\calS\in \calC_n
\label{EquationMap}
\eeq

\noindent is minimized over all $k$-subsets of $\calS$ when the nodes in $\calS$ are evenly distributed on the cycle $\calC_n$.
\label{Theorem3}
\end{thm}

The function $G$ in (\ref{EquationMap}) indicates the expected amount of time to reach $s$ for uniformly random chosen initial points $X_0 \in \calC_n$.

%An example of is shown below (here $n=10$, $|\calS|=5$, $s=0$).
Example. Suppose $n=10$, $|\calS|=5$ and $s=0$. In Table \ref{Example3Table}, we give $G(\calS)$  for some subsets $\calS\subset \calC_n$. Thee are $16$ distinct values of $G(\calS)$ , and one set $\calS$ is included for each of these values.

\begin{table}[H]
\begin{center}
\begin{tabular}{| c || c| c | c | c | c | c | c | c | c | c || c |}
  \hline
& $s$ & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & $G(\calS)$ \\
  \hline
1   &  1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 2.9 \\
2   &  1 & 1 & 0 & 1 & 0 & 0 & 1 & 0 & 1 & 0 & 3.0 \\
3   &  1 & 1 & 0 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 3.1 \\
4   &  1 & 1 & 0 & 1 & 0 & 1 & 0 & 0 & 1 & 0 & 3.2 \\
5   &  1 & 1 & 0 & 1 & 0 & 0 & 0 & 1 & 1 & 0 & 3.3 \\
6   &  1 & 1 & 1 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 3.4 \\
7   &  1 & 1 & 1 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 3.5 \\
8   &  1 & 1 & 1 & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 3.6 \\
9   &  1 & 1 & 1 & 1 & 0 & 0 & 1 & 0 & 0 & 0 & 3.7 \\
10   &  1 & 1 & 1 & 0 & 0 & 1 & 1 & 0 & 0 & 0 & 3.9 \\
11   &  1 & 1 & 1 & 0 & 0 & 0 & 0 & 1 & 1 & 0 & 4.0 \\
12   &  1 & 1 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 4.2 \\
13   &  1 & 1 & 1 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 4.6 \\
14   &  1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 5.1 \\
15   &  1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 1 & 5.2 \\
16   &  1 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 5.5\\
\hline
\end{tabular}
\end{center}
\caption[Values of $f$ and $G$ for $n=10$, $k=5$ and $s=0$.]{Values of $f$ and $G$ for $n=10$, $k=5$ and $s=0$. One set $\calS$ is given for each of the sixteen distinct values of $G(\calS)$.}
\label{Example3Table}
\end{table}

In Table \ref{Example3Table}, $f(i)=1$ denotes that the vertex $i$ contains a ``map", while $f(i)=0$ denotes that the vertex does not contain a ``map". Note that $G(\calS)$ is smallest for evenly distributed sets $\calS$ and largest for ``clustered" sets $\calS$.
%
%Note that we just list out those placement with different $G(\calS)$ values.

We require the following two lemmas.

\begin{lem}
Suppose $s_1,s_2\in \calS$, $s_1 < s_2$ and $\calI=(s_1,s_2)=\{s_1+1,s_1+2,\dots,s_2-1\}$ satisfies $\calI \cap \calS = \emptyset$. In addition, set
\beq
a=dist(s_1,s) ~~~\mbox{   and   }~~~b=dist(s_2,s).
\eeq
We have
\beq
\frac{1}{|\calI|}\sum\limits_{i\in \calI} E\left(W|X_0=i\right) &=&\frac{d^2+d}{6}+\frac{a+b}{2},
\eeq
\noindent where
\beq
d=dist(s_1,s_2)=|\calI|+1.
\eeq
\label{Lemma4}
\end{lem}

\noindent{\bf Proof}.
Without loss of generality, we assume $a \leq b$,
which means that vertex $s_1$ is at least as close to $s$
as is vertex $s_2$.
\noindent Define
\beq
K\stackrel{def}{=}&\frac{1}{d-1}\sum\limits_{i\in \calI} E\left(W|X_0=i\right).
\label{Kabm}
\eeq
\noindent We consider the case of odd and even $d$, separately.

\noindent Case 1. When $d$ is even, say $d=dist(s_1,s_2)=2m$, there are $|\calI|=2m-1$ nodes between $s_1$ and $s_2$,
as shown in the table below

\begin{table}[H]
\begin{center}
\begin{tabular}{| c | c | c | c | c | c | c | c | c | c | c | c |}
\hline
$s$&$\cdots$&$s_1$&$s_1+1$&$\cdots$&$s_1+m$&$s_2-(m-1)$&$\cdots$
&$s_2-1$&$s_2$&$\cdots$  \\ \hline
$0$ &$\cdots$&$a$&$x_1$&$\cdots$&$x_m$&$y_{m-1}$&$\cdots$
&$y_1$&$b$&$\cdots$  \\
\hline
\end{tabular}
\end{center}
\caption[Setup for Case 1 ($d=2m$) in the proof of Lemma \ref{Lemma4}.]{Setup for Case 1 ($d=2m$) in the proof of Lemma \ref{Lemma4}, where $\{x_i\}$ and $\{y_j\}$ are the expected values in (\ref{xmym}).}
\label{dIsEven}
\end{table}
In Table \ref{dIsEven},
\beq
x_i&\stackrel{def}{=}&E(W|X_0=s_1+i),~~~0\leq i\leq m, \nonumber \\
y_j&\stackrel{def}{=}&E(W|X_0=s_2-j),~~~0\leq j\leq m-1. \nonumber \\
\label{xmym}
\eeq
\noindent Note that the since $s_1, s_2\in \calS$, $x_0=E(W|X_0=s_1)=a$, $y_0=E(W|X_0=s_2)=b$.

We claim
\begin{align*}
x_1 &=a+\Delta_1,  &  x_i &= a+i\Delta_1-2{i \choose 2} \\
y_1 &=b+\Delta_2,  &  y_j &= b+j\Delta_2-2{j \choose 2},
\end{align*}
\noindent for $2 \leq i \leq m$, $2 \leq j \leq m-1$, where
$\Delta_1$ and $\Delta_2$ are constants (depending on $m$) that
are to be determined later.

One can easily verify that
\beq
x_1=1+\frac{1}{2}\left(a+x_2\right), \\
y_1=1+\frac{1}{2}\left(b+y_2\right),
\eeq
\noindent and, for $i=2,3,\cdots,m-1$, and $j=2,3,\cdots,m-2$,\, \beq
x_i=1+\frac{1}{2}\left(x_{i-1}+x_{i+1}\right), \\
y_j=1+\frac{1}{2}\left(y_{j-1}+y_{j+1}\right),
\eeq
\noindent as is required for the expected values $a, x_1, x_2, \cdots, x_m, y_{m-1}, y_{m-2}, \cdots, y_1, b$ (by conditioning).

We solve the remaining two equations
\beq
x_m &=& 1 + \frac{1}{2}\left(x_{m-1} + y_{m-1}\right), \\
y_{m-1} &=& 1 + \frac{1}{2}\left(x_m + y_{m-2}\right),
\eeq
\noindent for $\Delta_1$ and $\Delta_2$, to obtain
\beq
\Delta_1 &=& 2m-1-\frac{a-b}{2m}, \\
\Delta_2 &=& 2m-1+\frac{a-b}{2m}.
\eeq
\noindent Recalling that $d=2m$, we have
\beq
K
&=& \frac{1}{2m-1}\left(\sum\limits_{i=1}^m x_i + \sum\limits_{i=1}^{m-1} y_i\right) \nonumber \\
&=& \frac{1}{2m-1}\left(ma+\sum\limits_{i=1}^m\,i\Delta_1-\sum\limits_{i=2}^m{i \choose2}+ \left(m-1\right)b+\sum\limits_{i=1}^{m-1}\,i\Delta_2-\sum\limits_{i=2}^{m-1}{i \choose 2}\right) \nonumber \\
&=& \frac{1}{2m-1}\left(ma+mb-b+\frac{m\left(m+1\right)}{2}\Delta_1+\frac{m\left(m-1\right)}{2}\Delta_2\right.\nonumber \\
&&\left. -\frac{n\left(n-1\right)\left(n+1\right)}{3}+\frac{n\left(n-1\right)\left(n-2\right)}{3}\right) \nonumber \\
&=&\frac{ma+mb-b}{2m-1}+m^2-\frac{1}{2m-1}\frac{a-b}{2}-\frac{m\left(m-1\right)}{3} \nonumber \\
%&=&m^2-\frac{m\left(m-1\right)}{3}+\frac{a+b}{2} \nonumber \\
&=&\frac{2m^2+m}{3}+\frac{a+b}{2} \nonumber \\
&=&\frac{\left(2m\right)^2+2m}{6}+\frac{a+b}{2} \nonumber \\
&=&\frac{d^2+d}{6}+\frac{a+b}{2},
\label{KDequal2m}
\eeq
\noindent as required. Note that to obtain the third equality in (\ref{KDequal2m}), we employed the formula
$
\sum\limits_{i=2}^n{i \choose 2}
%=\frac{1}{2}\left(1\times2+2\times3+\cdots+\left(n-1\right)n\right)
=\frac{n\left(n-1\right)\left(n+1\right)}{3}.
$

\noindent Case 2. When $d$ is odd, say $d=2m+1$, then there are
$|\calI|=2m$ nodes between $s_1$ and $s_2$, as shown in the table below:

\begin{table}[H]
\begin{center}
\begin{tabular}{| c | c | c | c | c | c | c | c | c | c | c | c |}
\hline
$s$&$\cdots$&$s_1$&$s_1+1$&$\cdots$&$s_1+m$&$s_2-m$&$\cdots$
&$s_2-1$&$s_2$&$\cdots$  \\ \hline
$0$ &$\cdots$&$a$&$x_1$&$\cdots$&$x_m$&$y_m$&$\cdots$
&$y_1$&$b$&$\cdots$  \\
\hline
\end{tabular}
\end{center}
\caption[Setup for Case 2 ($d=2m+1$) in the proof of Lemma \ref{Lemma4}.]{Setup for Case 2 ($d=2m+1$) in the proof of Lemma \ref{Lemma4}, where $\{x_i\}$ and $\{y_j\}$ are the expected values in (\ref{xmymd2madd1}). }
\label{dIsOdd}
\end{table}
As in (\ref{xmym}),
\beq
x_i&\stackrel{def}{=}&E(W|X_0=s_1+i),~~~0\leq i\leq m, \nonumber \\
y_j&\stackrel{def}{=}&E(W|X_0=s_2-j),~~~0\leq j\leq m. \nonumber \\
\label{xmymd2madd1}
\eeq
\noindent We again assume that
\begin{align*}
x_1 &=a+\Delta_1,  &  x_i &= a+i\Delta_1-2{i \choose 2}, \\
y_1 &=b+\Delta_2,  &  y_j &= b+j\Delta_2-2{j \choose 2},
\end{align*}

\noindent where $2 \leq i,j \leq m$,
$\Delta_1$ and $\Delta_2$ are to be determined.

Solving the equations
\beq
x_m &=& 1 + \frac{1}{2}\left(x_{m-1} + y_m\right), \\
y_m &=& 1 + \frac{1}{2}\left(x_m + y_{m-1}\right),
\eeq

\noindent for $\Delta_1$ and $\Delta_2$, we obtain
\beq
\Delta_1 &=& 2m-\frac{a-b}{2m+1}, \\
\Delta_2 &=& 2m+\frac{a-b}{2m+1}.
\eeq

\noindent Thus, as in (\ref{KDequal2m}), we have
\beq
K
&=&\frac{1}{2m}\left(\sum\limits_{i=1}^m x_i+\sum\limits_{i=1}^m y_i\right) \nonumber \\
&=& \frac{1}{2m}\left(ma+\sum\limits_{i=1}^m\,i\Delta_1-\sum\limits_{i=2}^m{i \choose 2}+mb+\sum\limits_{i=1}^m\,i\Delta_2-\sum\limits_{i=2}^m{i \choose 2}\right) \nonumber \\
&=& \frac{1}{2m}\left(ma+mb+\frac{m\left(m+1\right)}{2}\left(\Delta_1+\Delta_2\right)-2\sum\limits_{i=2}^m{i \choose 2}\right) \nonumber \\
&=&m\left(m+1\right)-\frac{\left(m-1\right)\left(m+1\right)}{3}+\frac{a+b}{2} \nonumber \\
&=&\frac{2m^2+3m+1}{3}+\frac{a+b}{2} \nonumber \\
&=&\frac{\left(2m+1\right)^2+\left(2m+1\right)}{6}+\frac{a+b}{2} \nonumber \\
&=&\frac{d^2+d}{6}+\frac{a+b}{2},
\eeq
\noindent and the result is proven.
\qed

We now have a technical lemma which is valuable in the proof of Theorem \ref{Theorem3}.

\begin{lem}
Suppose $s_1, s^* ,s_2\in \calS$, $s_1<s^*<s_2$, and
\beq
(s_1,s_2) \cap \calS = s^*.
\eeq
\noindent where $(s_1,s_2)$ is as in the statement of Lemma \ref{Lemma4}. Set $a=dist(s_1,s)$, $b=dist(s_2,s)$ and $r=dist(s^*,s_1)$. Then
\beq
\sum\limits_{i\in \left[s_1,s_2\right]}E(W|X_0=i)
\label{4H}
\eeq
\noindent is minimized when $r=\frac{d-1}{2}+\frac{b-a}{2d}$, where $d=dist(s_1,s_2)$.
\label{ThreeElementsLemma}
\end{lem}

The proof of Theorem \ref{Theorem3} follows immediately from Lemma \ref{ThreeElementsLemma}. For arbitrary subsets of $\calS$, of size $k$, on the cycle, we only need to recursively adjust the relative
position of any consecutively indexed three elements of $\calS$, by moving the inner element to the middle position of the interval constructed by the other two elements.

\noindent{\bf Proof of Lemma \ref{ThreeElementsLemma}}. By Lemma \ref{Lemma4}, we have that the value $K$ in (\ref{Kabm}) is only dependent on $a$ and $b$ via their sum. As before without loss of generality, we assume $b \geq a$.

For the case $b=a+d$, which implies that the exact distances of the vertices between $s_1$ and $s_2$, to $s$ are increasing, as shown in Table \ref{aEqualTo1}, and $dist(s,s^*)=a+r$.

\begin{table}[H]
\begin{center}
\begin{tabular}{| c | c | c | c | c | c | c | c | c | c | c |}
\hline
$s$ & $\cdots$ &$s_1$&$\cdots$&$s^*$&$\cdots$&$s_2$&$\cdots$&$\cdots$  \\ \hline
$0$& $\cdots$ & $a$&$\cdots$&$a+r$&$\cdots$&$b$&$\cdots$&$\cdots$  \\ \hline
\end{tabular}
\end{center}
\caption{The case $b=a+d$ in the proof of Lemma \ref{ThreeElementsLemma}.}
\label{aEqualTo1}
\end{table}

\begin{figure}[H]
\begin{center}
\begin{tikzpicture}
\path[draw] (0,0) node[below] {$s_1$} -- (3,1.5)node[above left]{$s^*$} -- (6,3) node[below] {$s_2$};
\end{tikzpicture}
\caption[The case $b=a+d$ in the proof of Lemma \ref{ThreeElementsLemma}.]{The case $b=a+d$ in the proof of Lemma \ref{ThreeElementsLemma}. The height is intended to indicate the distance to $s$. }
\label{figure3}
\end{center}
\end{figure}

Here $dist(s_1,s^*)=r$ and there are $r-1$ nodes
in between $s_1$ and $s^*$, thus
\beq
dist(s^*,s_2)&=&b-(a+r)=d-r
\eeq
\noindent and there  are $d-r-1$ nodes in between $s^*$ and $s_2$. Thus employing (\ref{Kabm}), the total number of expected steps in (\ref{4H}), denoted as $H$, is given by
\beq
H&=&a+\left(r-1\right)\left(\frac{r^2+r}{6}+\frac{a+a+r}{2}\right)+(a+r)\nonumber\\
&&+\left(d-r-1\right)\left(\frac{\left(d-r\right)^2+d-r}{6}+\frac{a+r+b}{2}\right)+b.
\label{Fabrm}
\eeq
Taking the first derivative with respect to $r$ in (\ref{Fabrm}), gives
\beq
\frac{\partial H}{\partial r} &=& dr-\frac{1}{2}d^2+\frac{1}{2}d+\frac{1}{2}a-\frac{1}{2}b.
\label{partialDFR}
\eeq
\noindent Setting the derivative in (\ref{partialDFR}) to zero and solving for $r$, we obtain the optimal position when $b=a+d$, i.e.
\beq
r&=&\frac{d-1}{2}+\frac{b-a}{2d}.
\label{OptimalRabm}
\eeq
In particular since $b=a+d$, we have $r=\frac{d}{2}$. It can be verified as in (\ref{SecondDeviativeOfG2prime}) that $r$ in (\ref{OptimalRabm}) is a minimal.

Now, assume $a \leq b \leq d+a-1$. Then as in Figure \ref{Figure1}, we have a vertex $P$ which is the furthest node from $s$. Without loss of generality, we will assume that the length of the left ``arm" $s_1P$ is no smaller than the length of the right ``arm" $Ps_2$ (they are equal when $a=b$).

\begin{figure}[H]
\begin{center}
\begin{tikzpicture}
\path[draw] (1,1) node[below] {$s_1$} -- (3,3) node[above left]{$s^*$} -- (4,4)node[above right]{P} -- (6,2) node[below]{$s_2$};
\end{tikzpicture}
\caption[The case $b\leq d+a-1$ in the proof of Lemma \ref{ThreeElementsLemma}.]{The case $b\leq d+a-1$ in the proof of Lemma \ref{ThreeElementsLemma}. The height is intended to indicate the distance to $s$.}
\label{Figure1}
\end{center}
\end{figure}


We will show that the optimal position for this situation is
again $r=\frac{d-1}{2}+\frac{b-a}{2d}$ as in (\ref{OptimalRabm}).

To prove this, we will show that the optimal position must locate
on the longer ``arm". In order to achieve this, consider
$H$ in (\ref{Fabrm}) as a function of $s^*$, and consider two possible values $s_1^*$, $s_2^*$ with corresponding distances $r^*=dist(s_1,s_1^*)=dist(s_2,s_2^*)$ as depicted in Figure \ref{Figure2}. We will show that
\beq
H(s_1^*) &\leq& H(s_2^*).
\eeq

\begin{figure}[H]
\begin{center}
\begin{tikzpicture}
\path[draw] (1,1) node[below]{$s_1$} -- (1.5,1.5) node[above left]{$r^*$} -- (4,4)node[above right]{P} -- (5.5,2.5)node[above right]{$r^*$}--(6,2) node[below]{$s_2$};
\path[draw] (2,2)node[above left]{$s_1^*$} -- (5,3)node[above right]{$s_2^*$};
\end{tikzpicture}
\caption[The case $b\leq d+a-1$ in the proof of Lemma \ref{ThreeElementsLemma}.]{The case $b\leq d+a-1$ in the proof of Lemma \ref{ThreeElementsLemma}. The height is intended to indicate distance to $s$. Here, $r^*=dist(s_1,s_1^*)=dist(s_2,s_2^*)$. }
\label{Figure2}
\end{center}
\end{figure}


By Equation (\ref{Fabrm}), we have:
\beq
H(s_1^*)
&=&a+\left(r^*-1\right)\left(\frac{{r^*}^{2}+r^*}{6}+\frac{a+a+r^*}{2}\right)+(a+r^*) \nonumber \\
&&+\left(d-r^*-1\right)\left(\frac{\left(d-r^*\right)^2+d-r^*}{6}+\frac{a+r^*+b}{2}\right)+b, \nonumber \\
\eeq
\noindent and
\beq
H(s_2^*)
&=&a+\left(r^*-1\right)\left(\frac{{r^*}^2+r^*}{6}+\frac{b+b+r^*}{2}\right)+(b+r^*) \nonumber \\
&&+\left(d-r^*-1\right)\left(\frac{\left(d-r^*\right)^2+d-r^*}{6}+\frac{a+b+r^*}{2}\right)+b. \nonumber \\
\eeq
\noindent Hence,
\beq
H(s_1^*)-H(s_2^*)
&=&\left(r^*-1\right)\left(\frac{a+a+r^*}{2}-\frac{b+b+r^*}{2}\right)+a-b\nonumber \nonumber \\
&=& \left(r^*-1\right)\left(a-b\right)+a-b \nonumber \\
&=& r^*\left(a-b\right).
\eeq
\noindent The result follows since $b \geq a$ and $r^*\geq1$.
\qed

In the next chapter, we will consider accumulating pheromone.

%\noindent {\bf Proof of Theorem 3.1}.


\chapter{Contiguous sets $\calS$ on $\mathbb{Z}$ (accumulating pheromone)}

In this chapter, we will discuss when the graph $G$ is the set of integers $\mathbb{Z}$, $\calS$ is contiguous on $\mathbb{Z}$, and the pheromone is allowed to be accumulated. First, for a single random walk departing from $s=0$, define $U_i^{(k)}$, for $i\in \mathbb{Z}$ and $k\in\{1,2,3,\dots\}$ via
\beq
U_i^{(k)}=|\{0\leq t\leq k:X_t=i\}|
\eeq
\noindent i.e. the number of visits of the walk to vertex $i$ up to time $k$.

Note that all results in this chapter will carry over to the case where $\mathbb{Z}$ is replaced with an $n$-cycle as long as $n \geq 2k$. We begin with the following simple example.

\noindent {\bf Example 2}. Suppose $k=4$. There are $2^{k-1}=8$ possible paths that a walker can take. We denote a left move by $-1$ and a right move by $+1$ (the increments in the random walk), so that the possible equally likely paths are generated  through the sequences of moves $(+1, +1, +1)$, $(+1, +1, -1)$, $(+1, -1, +1)$, $(+1, -1, -1)$, $(-1, +1, +1)$, $(-1, +1, -1)$, $(-1, -1, +1)$ and $(-1, -1, -1)$.

We have the following table for $U_i^{(3)}$, for $-3\leq i \leq 3$.

\begin{table}[H]
\begin{center}
\begin{tabular}{|c|c|c||c|c|c|c|c|c|c|c|}
\hline
\multicolumn{3}{|c||}{increments} &$-3$&$-2$&$-1$&$0$&$1$&$2$&$3$ \\
\hline
$+1$&$+1$&$+1$ & $0$&$0$&$0$&$1$&$1$&$1$&1 \\
  \hline
$+1$&$+1$&$-1$ & $0$&$0$&$0$&$1$&$2$&$1$&0 \\
  \hline
$+1$&$-1$&$+1$ & $0$&$0$&$0$&$2$&$2$&$0$&0 \\
  \hline
$+1$&$-1$&$-1$ & $0$&$0$&$1$&$2$&$1$&$0$&0 \\
  \hline
$-1$&$+1$&$+1$ &  $0$&$0$&$1$&$2$&$1$&$0$&0 \\
  \hline
$-1$&$+1$&$-1$ & $0$&$0$&$2$&$2$&$0$&$0$&0 \\
  \hline
$-1$&$-1$&$+1$ & $0$&$1$&$2$&$1$&$0$&$0$&0 \\
  \hline
$-1$&$-1$&$-1$ & $1$&$1$&$1$&$1$&$0$&$0$&0 \\
  \hline
  \hline
\multicolumn{3}{|c||}{$E\left(U_i^{(3)}\right)$} &1/8&2/8&7/8&12/8&7/8&2/8&1/8 \\
  \hline
\end{tabular}
\caption{The values of $E\left(U_i^{(3)}\right)$, for $k=4$.} % title of Table
\label{TableKequal4}
\end{center}
\end{table}

In particular, consider $N$ simple random walks independently departing from $s=0$ and define $U_i^k\left(j\right)$ to be the value of $U_i^{\left(k\right)}$ for the $j$th walk. In addition set
\beq
S_i^k&=&\sum_{j=1}^N U_i^{(k)}(j)
\eeq
\noindent to be the number of visits to $i$ by time $k$ summed over all $N$ walks. In cases where later arriving walks are influenced by relative proportions of pheromone at neighbors, a quantity of interest would be
\beq
\beta_i^k&=&E\left(\frac{S_{i+1}^k}{S_{i-1}^k}\right).
\eeq

\noindent Note that by the strong law of large numbers (see for instance \cite[Theorem 22.1]{ConvergProbMeasure}),

\beq
\beta_i^k&\stackrel{a.c.}{\rightarrow}& \rho_{i,k}
\eeq

\noindent where
\beq
\rho_i^k&=& \frac{E(U_{i+1}^{(k)})}{E(U_{i-1}^{(k)})},
\label{Ratio1}
\eeq

\noindent and the quantity $1/(1+\rho_i^k)$ is indicative of the probability that a walker at $i$ moves to the left, at the next step, assuming pheromone directs the walker proportionally (where $0/0$ is take to be 1).
%Note that the quantity is not the same as $E\left(U_{i+1}^{(k)} / U_{i-1}^{(k)}\right)$

We have the table below for values of
\beq
u_{k,i}&=&2^{k-1}E(U_i^{(k)}),
\eeq
\noindent for small values of $k$. Since the walks under consideration are symmetric, we only include values of $u_{k,i}$ for $i\geq0$.


\begin{table}[H]
\begin{center}
\begin{tabular}{| l || c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c }
  \hline
$k/i$&$0$&$1$&$2$&$3$&$4$&$5$&$6$&$7$&$8$&$9$&$10$&$11$&$12$
\\  \hline
$1$&$1$&$0$&$0$&$0$&$0$&$0$&$0$&$0$&$0$&$0$&$0$&$0$&$0$
\\  \hline
$2$&$2$&$1$&$0$&$0$&$0$&$0$&$0$&$0$&$0$&$0$&$0$&$0$&$0$
\\  \hline
$3$&$6$&$2$&$1$&$0$&$0$&$0$&$0$&$0$&$0$&$0$&$0$&$0$&$0$
\\  \hline
$4$&$12$&$7$&$2$&$1$&$0$&$0$&$0$&$0$&$0$&$0$&$0$&$0$&$0$
\\  \hline
$5$&$30$&$14$&$8$&$2$&$1$&$0$&$0$&$0$&$0$&$0$&$0$&$0$&$0$
\\  \hline
$6$&$60$&$38$&$16$&$9$&$2$&$1$&$0$&$0$&$0$&$0$&$0$&$0$&$0$
\\  \hline
$7$&$140$&$76$&$47$&$18$&$10$&$2$&$1$&$0$&$0$&$0$&$0$&$0$&$0$
\\  \hline
$8$&$280$&$187$&$94$&$57$&$20$&$11$&$2$&$1$&$0$&$0$&$0$&$0$&$0$
\\  \hline
$9$&$630$&$374$&$244$&$114$&$68$&$22$&$12$&$2$&$1$&$0$&$0$&$0$&$0$
\\  \hline
$10$&$1260$&$874$&$488$&$312$&$136$&$80$&$24$&$13$&$2$&$1$&$0$&$0$&$0$
\\  \hline
$11$&$2772$&$1748$&$1186$&$624$&$392$&$160$&$93$&$26$&$14$&$2$&$1$&$0$&$0$
\\  \hline
$12$&$5544$&$3958$&$2372$&$1578$&$784$&$485$&$186$&$107$&$28$&$15$&$2$&$1$&$0$
\\  \hline
$13$&$12012$&$7916$&$5536$&$3156$&$2063$&$970$&$592$&$214$&$122$&$30$&$16$&$2$&$1$
\\  \hline
%    $\vdots$&$\vdots$&$\vdots$&$\vdots$&$\vdots$&$\vdots$&$\vdots$&
%    $\vdots$&$\vdots$&$\vdots$&$\vdots$&$\vdots$&$\vdots$&$\vdots$\\
%  \hline
\end{tabular}
\caption{Values of $u_{k,i}=2^{k-1}E(U_i^k)$ for $i\geq 0$ and small $k$.}
\label{TableA}
\end{center}
\end{table}

Some features in $\{u_{k,i}\}$ are apparent from Table \ref{TableA}, and we will state these as lemmas. We first provide some definitions.

\noindent {\bf Definition}. A {\it generating function} of a sequence $\{a_n\}_{n\geq 0}$ is a formal power series, $f$, given by
\beq
f\left(x\right)=a_0+a_1x+a_2x^2+\cdots+a_nx^n+\cdots.
\eeq
\noindent Similarly, a {\it bivariate generating function}, $F$, of a two-dimensional sequence $\{a_{m,n}\}_{m\geq 0;n\geq 0}$ is
\beq
F\left(x,y\right)=\sum\limits_{m=0}^{\infty}\sum\limits_{n=0}^{\infty}a_{m,n}x^my^n.
\eeq
\qed
\begin{lem}
The sequence $\{u_{k,i}\}$ in Table \ref{TableA} satisfies the following two properties.
\begin{enumerate}[(a)]
\item $u_{k,i}=u_{k-1,i-1}+u_{k-1,i+1},~~~k \geq 2,i > 0$;
\item $u_{2k+i-1,i}=2u_{2k+i-2,i},~~~k\geq 1, i\geq 0$.
\end{enumerate}
\label{Lemma6}
\end{lem}
\noindent {\bf Proof}. To prove (a), set
\beq
Z_i^n &=& \left\{
  \begin{array}{l l}
    1 & \quad \text{if $X_n=i$ } \\
    0 & \quad \text{otherwise}
\end{array} \right.
\eeq
\noindent and
\beq
z_i^n&=&E(Z_i^n)=P(X_n=i).
\eeq
\noindent Then
\beq
U_i^{\left(k\right)}&=&Z_i^0+Z_i^1+Z_i^2+\dots+Z_i^{k}.
\label{UUUUzzzz}
\eeq
\noindent For $i>0$, and $1\leq n \leq k$ by conditioning we have
\beq
z_i^n&=&\frac{1}{2}z_{i-1}^{n-1}+\frac{1}{2}z_{i+1}^{n-1},
\eeq
\noindent Then
\beq
u_{k,i}&=&2^{k-1}E(U_i^{\left(k\right)}) \nonumber \\
&=&2^{k-1}E\left(Z_i^0+Z_i^1+Z_i^2+\dots+Z_i^{k}\right) \nonumber \\
&=&2^{k-1}E\left[Z_i^0+\frac{1}{2}\left(Z_{i-1}^0+Z_{i+1}^0\right)+\frac{1}{2}\left(Z_{i-1}^1+Z_{i+1}^1\right)+\dots+\frac{1}{2}\left(Z_{i-1}^{k-1}+Z_{i+1}^{k-1}\right)\right] \nonumber \\
&=&2^{k-2}E\left(Z_{i-1}^0+Z_{i-1}^1+\dots+Z_{i-1}^{k-1}\right)+2^{k-2}E\left(Z_{i+1}^0+Z_{i+1}^1+\dots+Z_{i+1}^{k-1}\right) \nonumber \\
&=&2^{k-2}E(U_{i-1}^{(k-1)})+2^{k-2}E(U_{i+1}^{(k-1)}) \nonumber \\
&=&u_{k-1,i-1}+u_{k-1,i+1},
\label{ProofLemma6a}
\eeq
\noindent note that to obtain the fourth equality of (\ref{ProofLemma6a}) we employ the fact that $z_i^0 = 0$ for $i > 0$.

\noindent (b). Note that $z_i^n=0$ if $n$ and $i$ are of opposite parity. Thus from (\ref{UUUUzzzz}), we obtain
\beq
E\left(U_i^{(2k+i-1)}\right)
&=&z_i^0+z_i^1+z_i^2+\dots+z_i^{2k+i-2}+z_i^{2k+i-1}   \nonumber \\
&=&z_i^0+z_i^1+z_i^2+\dots+z_i^{2k+i-2}+0 \nonumber \\
&=&E(U_i^{(2k+i-2)}),
\eeq
\noindent since $i$ and $2k+i-1$ are opposite parity. Hence
\beq
u_{2k+i-1,i}&=&2^{2k+i-1}E(U_i^{(2k+i-1)}) \nonumber \\
&=&2\times2^{2k+i-2}E(U_i^{(2k+i-2)}) \nonumber \\
&=&2u_{2k+i-2,i}.
\eeq
\qed

Lemma 1 (b) suggests the transformation $\{t_{l,i}\}$ of $\{u_{k,i}\}$ given by
\beq
t_{l,i}&=&u_{2l+i-1,i},~~~l\geq 1, i\geq 0,
\label{TableT2TableA}
\eeq
\noindent as in Table \ref{TableTafdsafds}, below.

\begin{table}[H]
\begin{center}
\begin{tabular}{| l || c | c | c | c | c | c | c | c | c | c | }
  \hline
$l/i$&$0$&$1$&$2$&$3$&$4$&$5$&$6$&$7$
\\  \hline \hline
$1$&$1$&$1$&$1$&$1$&$1$&$1$&$1$&$1$
\\  \hline
$2$&$6$&$7$&$8$&$9$&$10$&$11$&$12$&$13$
\\  \hline
$3$&$30$&$38$&$47$&$57$&$68$&$80$&$93$&$107$
\\  \hline
$4$&$140$&$187$&$244$&$312$&$392$&$485$&$592$&$714$
\\  \hline
$5$&$630$&$874$&$1186$&$1578$&$2063$&$2655$&$592$&$4221$
\\  \hline
$6$&$2772$&$3958$&$5536$&$7599$&$10254$&$13623$&$17844$&$23072$
\\  \hline
$7$&$12012$&$17584$&$25147$&$35401$&$49024$&$66868$&$89940$&$119420$
\\  \hline
\end{tabular}
\end{center}
\caption{Values of $t_{l,i}$ for small $l$ and $i$.}
\label{TableTafdsafds}
\end{table}

We have the following lemma.

\begin{lem}
The generating function, $H_i$ for $\{t_{l,i}\}$ is given by
\beq
H_i(x)&\stackrel{def}{=}&\sum\limits_{l=1}^{\infty}t_{l,i}x^l =xg(x)c^i(x),~~~i \geq 0
\label{HiOfx}
\eeq
\noindent where $g$ and $c$ are defined as
\beq
g\left(x\right)&=&\frac{1}{\left(1-4x\right)^{\frac{3}{2}}},
\label{gOFx}
\eeq
\noindent and
\beq
c\left(x\right)&=&\frac{1-\sqrt{1-4x}}{2x}.
\label{cOFx}
\eeq
\label{Lemma7}
\end{lem}
\noindent Note that $c(x)$ is the generating function of the Catalan numbers \beq
\left[x^n\right]c\left(x\right)&=&\frac{1}{n+1}{2n\choose n},~~~n\geq 0
\eeq
\noindent (i.e. sequence A000108 in the On-line Encyclopedia of Integer Sequences \cite{A000108}).

\noindent {\bf Proof of Lemma {\ref{Lemma7}}}. We first prove (\ref{HiOfx}) for $i=0$.

\beq
t_{l+1,0}
&=&u_{2l+1,0} \nonumber \\
&=&2^{2l+1-1}E\left(\mbox{number of visits to } 0 \mbox{ by time }  2l \right) \nonumber \\
&=&2^{2l}\left[P(X_0=0)+P(X_2=0)+P(X_4=0)+\dots+P(X_{2l}=0)\right] \nonumber\\
&=&2^{2l}\left[1+\frac{{2\choose 1}}{2^2} + \frac{{4 \choose 2}}{2^4} + \dots + \frac{{2l\choose l}}{2^{2l}}\right] \nonumber \\
&=&2^{2l}\sum\limits_{j=0}^{l}\frac{{2j\choose j}}{2^{2j}} \nonumber \\
&=&\sum\limits_{j=0}^{l}4^{l-j}{2j\choose j}.
\eeq
\noindent Hence
\beq
H_0(x)&=&\sum\limits_{l=1}^{\infty}t_{l,0}x^l
=x\sum\limits_{l=0}^{\infty}t_{l+1,0}x^l
=x\sum\limits_{l=0}^{\infty}u_{2l+1,0}x^l \nonumber \\
&=& x \sum\limits_{l=0}^{\infty}\left(\sum\limits_{j=0}^{l}4^{l-j}{2j\choose j}\right)x^l \nonumber \\
&=& x\left(1+4x+16x^2+\dots\right)\left(1+{2\choose1}x+{4\choose2}x^2+\dots\right) \nonumber \\
&=&x\frac{1}{1-4x}\frac{1}{\left(1-4x\right)^{\frac{1}{2}}} \nonumber \\
&=& x g(x),
\label{HZero}
\eeq
\noindent where in obtaining the fourth equality in (\ref{HZero}), we applied the fact that the generating function for the sequence of central binomial coefficients
\beq
\left\{ {2n\choose n}\right \}_{n\geq0},
\eeq
\noindent is given by
\beq
\frac{1}{\left(1-4x\right)^{\frac{1}{2}}},
\eeq
\noindent see for instance \cite{CentralCoefficients}.

Next, define
\beq
\lambda_i&=& \min \left\{t: X_t=i | X_0=0\right \},
\eeq
\noindent which indicates the first time the random walk $\{X_t\}$ visits $i$. Let $\phi_i$ be the generating function for $\left\{P\left(\lambda_i=j\right)\right\}$, then $\phi_1$ is given by (see for instance \cite[Theorem 5.3.5(b)]{Grimmett})
\beq
\phi_1(x) &=& P(\lambda_1=1)x+P(\lambda_1=2)x^2+P(\lambda_1=3)x^3+\dots \nonumber \\
&=& \frac{1}{2}x+\frac{1}{8}x^3+\frac{1}{16}x^5+\frac{5}{128}x^7 \dots \nonumber \\
&=&\frac{1-\sqrt{1-x^2}}{x}.
%\label{DefinitionOfPhiX}
\eeq

We have
\beq
t_{l+1,1}
&=&u_{2l+2,1} \nonumber \\
&=&2^{2l+1}E\left(\mbox{number of visits to } 1 \mbox{ by time } 2l+1 \right)  \nonumber \\
&=& 2^{2l+1}P(\lambda_1=1)E\left(\mbox{number of visits to } 0 \mbox{ by time } 2l \right) \nonumber \\
&&+ 2^{2l+1}P(\lambda_1=2)E\left(\mbox{number of visits to } 0 \mbox{ by time } 2l-1 \right) \nonumber \\
&&+ 2^{2l+1}P(\lambda_1=3)E\left(\mbox{number of visits to } 0 \mbox{ by time } 2l-2 \right) \nonumber \\
&&\vdots \nonumber \\
&&+ 2^{2l+1}P(\lambda_1=2l+1)E\left(\mbox{number of visits to } 0 \mbox{ by time } 0 \right) \nonumber \\
&=&2^{2l+1}\left[P(\lambda_1=1)\frac{u_{2l+1,0}}{2^{2l}}+0+P(\lambda_1=3)\frac{u_{2l-1,0}}{2^{2l-2}}+0+\dots+\right. \nonumber \\
&& \left. +0+P(\lambda_1=2l+1)\frac{u_{1,0}}{2^{0}}\right] \nonumber \\
&=&\sum\limits_{j=0}^{l}2^{2l-2j+1}P(\lambda_1=2l-2j+1)u_{2j+1,0} \nonumber \\
&=&\sum\limits_{j=0}^{l}q_{2l-2j+1}u_{2j+1,0},
\eeq
\noindent where
\beq
q_n&\stackrel{def}{=}&2^nP(\lambda_1=n).
\eeq

\noindent Hence,
\beq
H_1(x)&\stackrel{def}{=}&\sum\limits_{l=1}^{\infty}t_{l,1}x^l
=x \sum\limits_{l=0}^{\infty}t_{l+1,1}x^l
=x \sum\limits_{l=0}^{\infty}u_{2l+2,1}x^l \nonumber \\
&=& x \sum\limits_{l=0}^{\infty}\left(\sum\limits_{j=0}^{l}q_{2l-2j+1}u_{2j+1,0}\right)x^l \nonumber \\
&=&x(q_1+q_3x+q_5x^2+\dots)(u_{1,0}+u_{3,0}x+u_{5,0}x^2+\dots) \nonumber \\
&=&xg(x)(q_1+q_3x+q_5x^2+\dots).
\label{HOne}
\eeq
%\noindent By (\ref{DefinitionOfPhiX}) we have
\beq
\phi_1(2x)&=&q_1x+q_3x^3+q_5x^5+q_7x^7\dots.
\label{phi11111}
\eeq
\noindent Thus dividing by $x$ and substituting $x$ with $\sqrt{x}$ in (\ref{phi11111}), we obtain
\beq
q_1+q_3x+q_5x^2+\dots &=& \frac{\phi_1\left(2\sqrt{x}\right)}{\sqrt{x}} \nonumber \\
&=&\frac{1-\sqrt{1-4x}}{2x} \nonumber \\
&=&c(x) \label{ken}
\eeq
\noindent and
\beq
H_1(x)=xg(x)c(x),
\eeq
\noindent as required.

For $ i \geq 2$, the result follows similarly by employing the fact that
\beq
\phi_i&=&[\phi_1(x)]^i
\eeq
\noindent (see for instance \cite[Theorem 5.3.5(a)]{Grimmett}).
\qed

\noindent It can be verified that for $i\geq0$
\beq
c_n^i &\stackrel{def}{=}& \left[x^n\right]c^i\left(x\right) = \frac{i}{n+i}{2n+i-1, \choose n},~~~n\geq 0 \label{cni} \\
g_n &\stackrel{def}{=}& \left[x^n\right]g\left(x\right)=\left(n+1\right){2n+1 \choose n},~~~n\geq 0, \label{gni}
\eeq

\begin{cor}
The sequence $\{u_{k,0}\}$ has the generating function
\beq
\sum\limits_{k=0}^{\infty}u_{k,0}x^k &=& {\frac{x}{\left(1-2x\right)\sqrt{1-4x^2}}},
\eeq
\noindent and the sequence $\{u_{k,1}\}$ has generating function
\beq
\sum\limits_{k=0}^{\infty}u_{k,1}x^k
&=&\frac{1-\sqrt{1-4x^2}}{2\left(1-2x\right)^{\frac{3}{2}}\sqrt{1+2x}}.
\eeq
\label{corollary2}
\end{cor}
\noindent {\bf Proof}. It follows from (\ref{TableT2TableA}) that
\beq
t_{l,0}&=&u_{2l-1,0} \\
t_{l,1}&=&u_{2l,1}.
\eeq
\noindent Thus, employing Lemma \ref{Lemma6} (b), we have
\beq
\sum\limits_{k=0}^{\infty}u_{k,1}x^k
&=& 2H_0\left(x^2\right)+\frac{H_0\left(x^2\right)}{x} \nonumber \\
&=& \frac{\left(2x+1\right)}{x}\frac{x^2}{\left(1-4x^2\right)^{\frac{3}{2}}} \nonumber \\
&=& {\frac{x}{\left(1-2x\right)\sqrt{1-4x^2}}},
\eeq
\noindent and
\beq
\sum\limits_{k=0}^{\infty}u_{k,1}x^k
&=& H_1\left(x^2\right)+2xH_1\left(x^2\right) \nonumber \\
&=& \left(1+2x\right)\frac{x^2\,c\left(x^2\right)}{\left(1-4x^2\right)^{\frac{3}{2}}} \nonumber \\
&=& \frac{1-\sqrt{1-4x^2}}{2\left(1-2x\right)^{\frac{3}{2}}\sqrt{1+2x}}.
\eeq
\qed

We have the following theorem.

\begin{thm}
The bivariate generating function, $F$, of $\{u_{k,i}\}_{k\geq1;i\geq0}$ is given by
\beq
F(x,y)&=&\frac{x\left(2x-y-y\sqrt{1-4^2}\right)}{2\left(1-2x\right)^{\frac{3}{2}}\sqrt{1+2x}\left(x-y+xy^2\right)}.
\eeq
\end{thm}

\noindent {\bf Proof}. Setting $I=F(x,y)$, we have
\beq
I
&=&\sum\limits_{k=1}^{\infty} \sum\limits_{i=0}^{\infty}\,u_{k,i}x^ky^i \nonumber \\
&=&\sum\limits_{k=2}^{\infty} \sum\limits_{i=0}^{\infty}\,u_{k,i}x^ky^i
+\sum\limits_{i=0}^{\infty}\,u_{1,i}x^1y^i  \nonumber \\
&=&\sum\limits_{k=2}^{\infty} \sum\limits_{i=1}^{\infty}\,u_{k,i}x^ky^i+ \sum\limits_{k=2}^{\infty}\,u_{m,0}x^my^0+\sum\limits_{i=0}^{\infty}\,u_{1,i}x^1y^i \nonumber \\
&=&\sum\limits_{k=2}^{\infty} \sum\limits_{i=1}^{\infty}\,\left(u_{k-1,i-1}+u_{k-1,i+1}\right)x^ky^i
    +\left(\sum\limits_{k=1}^{\infty}\,u_{k,0}x^k - u_{1,0}x\right)+x \nonumber\\
&=&\sum\limits_{k=2}^{\infty} \sum\limits_{i=1}^{\infty}\,u_{k-1,i-1}x^ky^i
    +\sum\limits_{k=2}^{\infty}\sum\limits_{i=1}^{\infty}\,u_{k-1,i+1}x^ky^i
    +\sum\limits_{k=1}^{\infty}\,u_{k,0}x^k \nonumber \\
&=&\sum\limits_{k=1}^{\infty} \sum\limits_{i=1}^{\infty}\,u_{k,i-1}x^{k+1}y^i
    +\sum\limits_{k=1}^{\infty} \sum\limits_{i=1}^{\infty}\,u_{k,i+1}x^{k+1}y^i
    +\sum\limits_{k=1}^{\infty}\,u_{k,1}x^k \nonumber \\
&=&\sum\limits_{k=1}^{\infty} \sum\limits_{i=0}^{\infty}\,u_{k,i}x^{k+1}y^{i+1}
 + \sum\limits_{k=1}^{\infty} \sum\limits_{i=2}^{\infty}\,u_{k,i}x^{k+1}y^{i-1}
 + \sum\limits_{k=1}^{\infty}\,u_{k,0}x^k \nonumber \\
 &=&xyI+\sum\limits_{k=1}^{\infty}\sum\limits_{i=0}^{\infty}\,u_{k,i}x^{k+1}y^{i-1}
 - \sum\limits_{k=1}^{\infty}\,u_{k,0}x^{k+1}y^{-1} - \sum\limits_{k=1}^{\infty}\,u_{k,1}x^{k+1}y^0
 + \sum\limits_{k=1}^{\infty}\,u_{k,0}x^k \nonumber \\
 &=&xyI + \frac{x}{y}I - x\left(\sum\limits_{k=1}^{\infty}\,u_{k,1}x^k\right)
 + \left(1-\frac{x}{y}\right)\left(\sum\limits_{k=1}^{\infty}\,u_{k,0}x^k\right), \nonumber \\
\eeq
\noindent where the fourth equality follows from Lemma \ref{Lemma6} (a). By Corollary \ref{corollary2}, we have
\beq
\left(1-xy-\frac{x}{y}\right)I &=& \left(1-\frac{x}{y}\right)\frac{x}{\left(1-2x\right)\sqrt{1-4x^2}}
-x\frac{1-\sqrt{1-4x^2}}{2\left(1-2x\right)^{\frac{3}{2}}\sqrt{1+2x}} \nonumber \\
I&=&
\frac{1}{1-xy-\frac{x}{y}}\left[{\frac{\left(1-\frac{x}{y}\right)x}{\left(1-2x\right)\sqrt{1-4x^2}}}-
    \frac{x\left(1-\sqrt{1-4x^2}\right)}{2\left(1-2x\right)^{\frac{3}{2}}\sqrt{1+2x}}\right] \nonumber \\
I&=&
\frac{x\left(2x-y-y\sqrt{1-4^2}\right)}{2\left(1-2x\right)^{\frac{3}{2}}\sqrt{1+2x}\left(x-y+xy^2\right)},
\eeq
\noindent as required.
\qed

In what follows, for the ease of notation, we will use $u(k,i)$ and $t(l,i)$ in place of $u_{k,i}$ and $t_{l,i}$, respectively.
Now suppose that the number $N$ of original walkers is large, and a later visiting walker is at node $i$ at time $t$, where $0\leq i \leq k$. If the walker is influenced by pheromone proportionably, i.e.
\beq
P\left(Y_{t+1}=i+1|Y_t=i\right) &=& \frac{S_{i+1}^k}{S_{i-1}^k+S_{i+1}^k},
\eeq
\noindent the quantity $\rho_i^k$ in (\ref{Ratio1}), i.e.
\beq
\rho_i^k &\stackrel{def}{=}& \frac{u(k,i+1)}{u(k,i-1)}.
\label{ProbablityRatio}
\eeq
\noindent is of interest. We have the following conjecture.

\begin{conj}
For fixed $J \geq 1$, we have
\beq
\lim_{\substack{v \to +\infty \\ 2vJ \in \mathbb{Z}^+}} \rho_{2v}^{2vJ}&=&\frac{J-1}{J+1},
\eeq
\label{conj2}
\end{conj}
\qed

This chapter concludes with some development regarding Conjecture \ref{conj2}. By Equation (\ref{TableT2TableA}), we have
\beq
u(k,i)&=&t\left(\left\lceil\frac{k-i}{2}\right\rceil,i\right).
\eeq
\noindent Thus
\beq
\rho_i^k =\frac{u\left(k,i+1\right)}{u\left(k,i-1\right)} &=&
\frac{t\left(\left\lceil\frac{k-i-1}{2}\right\rceil,i+1\right)}{t\left(\left\lceil\frac{k-i+1}{2}\right\rceil,i-1\right)}.
\label{MappingEquation}
\eeq

By Lemma \ref{Lemma7}, (\ref{cni}) and (\ref{gni}), we have
\beq
t(l,i)&=&[x^l]xc^i\left(x\right)g\left(x\right) \nonumber \\
&=&\sum\limits_{n=0}^{l-1}g_{l-1-n}c_n^i \nonumber \\
&=&\sum\limits_{n=0}^{l-1}(l-n){2l-2n-1\choose l-n-1}\frac{i}{n+i}{2n+i-1\choose n} \nonumber \\
&=&\sum\limits_{n=0}^{l-1}\frac{\left(2l-2n-1\right)!}{\left(l-n-1\right)!\left(l-n-1\right)!}\frac{\left(2n+i-1\right)!}{\left(n+i-1\right)!}\frac{i}{n!}.
\label{Formular4Tjv}
\eeq
Now, consider the right hand side of (\ref{MappingEquation}) with the ratio $J=l/i$ held constant, and $l$ and $i$ even and tending to infinity ($i=2v$ and $l=2vJ$ for $v$ large). We have
\beq
\rho_{2v}^{2vJ}&=&\frac{t\left(v\left(J-1\right),2v\right)}{t\left(v\left(J-1\right)+1,2v-2\right)},
\eeq

\noindent Simplifying and employing (\ref{Formular4Tjv}), we obtain
\beq
\frac{t\left(v\left(J-1\right),2v\right)}{t\left(v\left(J-1\right)+1,2v-2\right)}&=&
\left(\frac{v\left(J-1\right)}{4vJ-4v+2}\right)\Omega(J,v), \nonumber \\
\label{ApplyHyperG}
\eeq
\noindent where
\beq
\Omega(J,v)&=&\frac{{}_3G_2\left(\left[v,1/2+v,-vJ+v+1\right],\left[2v+1,-vJ+v+1/2\right],1\right)}{{}_3G_2\left(\left[v-1,v-1/2,-vJ+v\right],\left[2v-1,-vj+v-1/2\right], 1\right)}, \nonumber \\
\eeq
\noindent and ${}_pG_q\left(\vec{n},\vec{d},z\right)$ is the generalized hypergeometric function,
$\vec{n}=\left[n_1,n_2,\dots,n_p\right]$,\,$\vec{d}=\left[d_1,d_2,\dots,d_q\right]$, defined by the series
\beq
{}_pG_q\left(\vec{n},\vec{d},z\right)
&=&\sum _{k=0}^{\infty} {\frac {{z}^{k}\prod _{i=1}^{p}\gamma\left( n_i,k\right) }{k!\,\prod _{j=1}^{q}\gamma\left( d_j,k\right) }},
\eeq

\noindent where $\gamma$ is the pochhammer function  defined for a positive integer $n$ and complex number $z$ as
\beq
\gamma\left(z,n\right)&=&z\left(z+1\right) \dots \left(z+n-1\right).
\eeq

Letting
\beq
K_J(v)&=&\rho_{2v}^{2vJ}.
\eeq

We have the following computations which are suggestive of the limit in Equation (\ref{ApplyHyperG}).

\begin{table}[H]
\begin{center}
\begin{tabular}{| c || c | c | c | c | c || c | }
  \hline
$J/K(v) $&$K(50)$&$K(100)$&$K(1000)$&$K(500000)$&$\frac{J-1}{J+1}$
\\  \hline \hline
$1.5$&$0.1939561424$&$0.1968928835$&$0.1996809675$&$0.1999993600$&$0.2$
\\  \hline
$2$&$0.3229862396$&$0.3279797619$&$0.3327799121$&$0.3333322222$&$0.3333333333$
\\  \hline
$5$&$0.6454217883$&$0.6553460763$&$0.6654547339$&$0.6666642223$&$0.6666666667$
\\  \hline
$10$&$0.7933001331$&$0.8044849608$&$0.8166442279$&$0.8181786943$&$0.8181818182$
\\  \hline
$100$&$0.9627669737$&$0.9692571415$&$0.9784715443$&$0.9801941199$&$0.9801980198$
\\ \hline
\end{tabular}
\end{center}
\caption{Values of $K_J(v)$ for varying $J$ and $v$.}
\label{VerifyJ}
\end{table}

Below is a plot of $K_5(v)$ for $v\leq 100$.

\begin{figure}
\begin{center}
\includegraphics[width=0.8\textwidth]{verifyJ.png}
\caption{Plot of $K_5(v)$ for $v\leq 100$.}
\label{graph2}
\end{center}
\end{figure}

\chapter{Conclusion and future research}


In Chapter 2, for consecutive non-accumulating pheromone on a cycle, we obtained that the optimal amount of pheromone should be approximately one third of the length of the cycle. In Chapter 3, for scattered maps deposited on the cycle, we determined that the optimal placement of those maps is evenly distributed. In Chapter 4, we discussed accumulating pheromone deposited on $\mathbb{Z}$,
determined the bivariate generating function for the two dimensional table of the accumulated pheromone values. We also provided a reasonable conjecture regarding limiting ratios of pheromone levels, for large numbers of independently depositing walkers.

In the future, we will be continuing work on random walks with pheromone on more general graphs, In addition, for scattered maps, we are interested in how the expected steps relates to the overall isolation and clustering of the maps. Preliminary work in this direction is suggestive of some interesting applications.

\begin{thebibliography}{99}

%these items are provided as samples

\bibitem{S. Camazine} S. Camazine, J.-L. Deneubourg, N. R. Franks, J. Sneyd,
G. Theraulaz, and E. Bonabeau (2001) {\em Self-Organization in
Biological Systems}, Princeton Univ Press.

\bibitem{A. Ghosh} A. Ghosh, A. Halder, M. Kothari and S. Ghosh, Aggregation pheromone density based data clustering. {\em Information
Sciences}, 178 13 (2008), pp. 2816-2831.

\bibitem{ConvergProbMeasure} Billingsley, Patrick (1999). {\em Convergence of Probability Measures}. New York, NY: John Wiley and Sons, Inc. ISBN 0-471-19745-9.

\bibitem{ProbabilityAndStatistics3rd} DeGroot, M., Schervish, M.: {\em Probability and Statistics}(Third Edition). Addison Wesley, Reading (2002).

\bibitem{CentralCoefficients} Kruchinin, Dmitry; Kruchinin, Vladimir {\em A method for obtaining generating functions for central coefficients of triangles}. J. Integer Seq. 15 (2012), no. 9, Article 12.9.3, 10 pp.


\bibitem{A000108} N. J. A. Sloane, {\em The On-Line Encyclopedia of Integer Sequences}, http://oeis.org/A000108.


\bibitem{CatalanConvolutionFormula} Regev, Alon A proof of Catalan's convolution formula. {\em Integers} {\bf 12} (2012), no. 5, 929C934.

\bibitem{Grimmett} Grimmett, Geoffrey R.; Stirzaker, David R. {\em Probability and random processes}. Third edition. Oxford University Press, New York, 2001.
\end{thebibliography}

\appendix
\vita
\chapter{Shuowen Wei}

Shuowen Wei is from from Guangshui, Hubei Province, P.R. China. He earned his bachelor's degree of Science from Wuhan University in Mathematics and Applied Mathematics. He will be continuing his studies in Wake Forest University Computer Science Department Master's program in the Fall of 2013.

\end{document}
